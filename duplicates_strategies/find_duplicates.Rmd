---
title: "Duplicates"
author: "Laura Menicacci"
date: "2023-01-13"
output: html_document
---

```{r}
library(tidyverse)
library(quanteda)
library(quanteda.textstats)
library(caret)
library(countrycode)

```

## Load data 

```{r}
ceres <- read_csv("C:\\Users\\laura\\OneDrive\\Documenti\\LAURA\\MCC\\futurelab_ceres\\ceres_versions\\ceres_thirdversion.csv")

lab_data <- read_csv("C:\\Users\\laura\\OneDrive\\Documenti\\LAURA\\MCC\\Policy databases\\duplicates_testsample.csv")

```

# Cosine similarity
```{r}
lab_data <- lab_data %>% 
  select(!`@dropdown`) %>% 
  tibble::rowid_to_column("index")

corp <- corpus(lab_data$policy_name) 
docnames(corp) <- paste(lab_data$index)

dfmat <- corp %>% tokens(remove_punc=TRUE) %>%
  dfm()

sim_mat <- textstat_simil(dfmat, method="cosine")
sim_df <- as.data.frame(sim_mat, upper=TRUE)

```

# Filter by cosine threshold, filter duplicates by country, label

We first remove the duplicates that have high score but different countries, since they are not duplicates. Then we label the dataset by inserting the index of similar policies as values in the column cos_dup. In this way, it is easier to inspect manually which policies are similar to which. 

```{r}
sim_filt <- sim_df %>% filter(cosine >= 0.7) # threshold for duplicate

lab_copy <- lab_data # create a copy 
lab_copy$cos_dup <- NA

for (i in 1:nrow(sim_filt)) {        # remove duplicates with different countries
  index1 = as.numeric(sim_filt[i,1])
  index2 = as.numeric(sim_filt[i,2])
  if(lab_copy[index1,2]!=lab_copy[index2,2]){
    sim_filt[i, 3] = NA
    sim_filt_2 <- na.omit(sim_filt)
    }
}
for (i in 1:nrow(sim_filt_2)){       # labeling 
  index1 = as.numeric(sim_filt_2[i,1])
  lab_copy[index1,14] = paste(lab_copy[index1,14], sim_filt_2[i,2], sep = ",")}

lab_copy$cos_dup <- trimws(lab_copy$cos_dup, whitespace = "NA,")


lab_copy$year_diff <- NA

for (i in 1:nrow(sim_filt_2)) {      # add indicator for duplicates with differing years
  index1 = as.numeric(sim_filt_2[i,1])
  index2 = as.numeric(sim_filt_2[i,2])
  if (is.na(lab_copy[i, 12])) {lab_copy$year_diff <- NA} 
  else {if (lab_copy[[index1,12]]!= lab_copy[[index2,12]]) {lab_copy[index1, 15] <- "year diff"}}
} # DOESN'T WORK BECAUSE THERE ARE NAs IN YEAR_ALL --> try overcoming with TRYCATCH ??? 
  
```

# Check performance of cosine similarity - accuracy score

74% accuracy without filtering for country and year - 60% cosine similarity threshold
```{r}
lab_copy_scores <- lab_copy %>% 
  mutate(cos_dup_n = ifelse(is.na(cos_dup) == F, 1, 0)) %>% 
  mutate(tp = duplicate == "yes" & is.na(cos_dup) == F) %>% 
  mutate(tn = duplicate == "no" & is.na(cos_dup) == T) %>% 
  mutate(fn = duplicate == "yes" & is.na(cos_dup) == T) %>% 
  mutate(fp = duplicate == "no" & is.na(cos_dup) == F) %>% 
  mutate(duplicate = ifelse(duplicate == "yes", 1, 0))
  
lab_copy_scores$tp <- ifelse(lab_copy_scores$tp == T, 1, 0)
lab_copy_scores$tn <- ifelse(lab_copy_scores$tn == T, 1, 0)
lab_copy_scores$fn <- ifelse(lab_copy_scores$fn == T, 1, 0)
lab_copy_scores$fp <- ifelse(lab_copy_scores$fp == T, 1, 0)


confmat <- table(lab_copy_scores$duplicate, lab_copy_scores$cos_dup_n) #confusion matrix

print(confmat)

# Accuracy = (TP+TN)/(TP+TN+FP+FN)

accuracy <- (57+72)/ (57 +72+15+15) 

print(accuracy) 

```

# Inspection of results

```{r}

lab_copy_scores %>% group_by(country) %>% 
  ggplot(aes(x = country, y = fn)) + geom_col() + ggtitle("Frequency of false negatives - duplicates not detected") + theme_bw()

lab_copy_scores %>% group_by(country) %>% 
  ggplot(aes(x = country, y = fp)) + geom_col() + ggtitle("Frequency of false positives - fake duplicates detected") + theme_bw()

lab_copy_scores %>% group_by(country) %>% 
  mutate(errors = fp+fn) %>% 
  ggplot(aes(x = country, y = errors)) + geom_col() + ggtitle("Error rate per country") + theme_bw()

```
# Remove/merge duplicates
```{r}
# from dup choose IEA and write in col datab indic = (IEA, CPD)


```


# Cosine similarity between policies of IEA and CPD

## Detection of IEA and CPD duplicates 
```{r}
ceres %>% group_by(indicator_database_source) %>% count() # 1544 UNFCCC in total - 1653 CPD +IEA
  
```
# cpd + iea prep & merging

```{r}

iea <- read_csv("C:/Users/laura/OneDrive/Documenti/LAURA/MCC/futurelab_ceres/policy_databases/policies_database_IEA_comma_utf8.csv")

iea_prep <- iea %>% 
  filter(grepl(c("Power, Heat and Utilities|Power generation|Electricity and heat generation|Combined heat and power"), Sectors)) %>% 
  select(Country, Year, Policy, Description, URL) %>% 
  mutate(country_code = countrycode(Country, origin = "country.name", destination = "iso3c")) %>%
  mutate(indicator_database_source = "IEA")

cpd <- read_csv("C:/Users/laura/OneDrive/Documenti/LAURA/MCC/futurelab_ceres/policy_databases/cpd.csv")

cpd_prep <- cpd %>% 
  select(Country, `Country ISO`, `Policy Title`, `Policy description`, `Date of decision`, `Start date of implementation`, `End date of implementation`,  `Source or references`) %>% 
  mutate(indicator_database_source = "Climate Policy Database")

iea_cpd <- full_join(iea_prep, cpd_prep, by = c("Country", "country_code" = "Country ISO", "Policy" = "Policy Title", "Description" = "Policy description", "Year" = "Start date of implementation", "URL" = "Source or references", "indicator_database_source" ))

iea_cpd <- iea_cpd %>% 
  rename(year = Year) %>% 
  rename(country = Country) %>% 
  rename(policy_name = "Policy") %>% 
  rename(policy_description = "Description") %>% 
  filter(country_code %in% c("AUS", "AUT","BEL", "CAN", "DNK", "FIN", "FRA", "DEU", "GRC",
                      "IRL", "ITA", "JPN", "LUX", "NLD", "NZL", "PRT", "ESP", "SWE",
                      "CHE", "GBR", "USA"))

#sim_new = sim_df
#
#for (i in 1:nrow(sim_new)) {
#  if (sim_new[i, 3] < 0.70){
#    sim_new[i, 3] = NA
#    sim_removed <- na.omit(sim_new)
#  }
#}
#
#
#for (i in 1:(nrow(sim_filt_2))) {  
#  index1 <- as.numeric(sim_filt_2[i, 2])
#  if (is.na(lab_copy$cos_dup[i])) {lab_copy$cos_dup[index1] <- paste(lab_copy$cos_dup[index1], #as.numeric(sim_filt_2[i,1]), sep = ",")} 
#  else {lab_copy$cos_dup[index1] <- paste(lab_copy$cos_dup[index1], as.numeric(sim_filt_2[i,1]), sep = ",")}
#}

```


# CPD + IEA Duplicates
```{r}

lab_data_c <- iea_cpd %>% 
  tibble::rowid_to_column("index")

corp <- corpus(lab_data_c$policy_name) 
docnames(corp) <- paste(lab_data_c$index)

dfmat <- corp %>% tokens(remove_punc=TRUE) %>%
  dfm()

sim_mat <- textstat_simil(dfmat, method="cosine")
sim_df <- as.data.frame(sim_mat, upper=TRUE)

sim_filt <- sim_df %>% filter(cosine == 1) # threshold for duplicate

lab_copy_c <- lab_data_c # create a copy 
lab_copy_c$cos_dup <- NA

for (i in 1:nrow(sim_filt)) {        # remove duplicates with different countries
  index1 = as.numeric(sim_filt[i,1])
  index2 = as.numeric(sim_filt[i,2])
  if(lab_copy_c[index1,2]!=lab_copy_c[index2,2]){
    sim_filt[i, 3] = NA
    sim_filt_2 <- na.omit(sim_filt)
    }
}
for (i in 1:nrow(sim_filt_2)){       # labeling 
  index1 = as.numeric(sim_filt_2[i,1])
  lab_copy_c[index1,11] = paste(lab_copy_c[index1,11], sim_filt_2[i,2], sep = ",")}

lab_copy_c$cos_dup <- trimws(lab_copy_c$cos_dup, whitespace = "NA,")

lab_copy_c %>% 
  mutate(cos_dup_n = ifelse(is.na(cos_dup) == F, 1, 0)) %>% 
  group_by(country) %>% 
  ggplot(aes(x = country, y = (cos_dup_n))) + geom_col(width = 0.8) + ggtitle("Detected dups per country - IEA + CPD") + theme_bw()

lab_copy_c %>% 
  mutate(cos_dup_n = ifelse(is.na(cos_dup) == F, 1, 0)) %>% 
  count(cos_dup_n)

lab_copy_c <- lab_copy_c %>% 
  filter(country == "Australia")
  

```



# CERES trial

```{r}
lab_data <- ceres %>% 
  tibble::rowid_to_column("index")

corp <- corpus(lab_data$policy_name) 
docnames(corp) <- paste(lab_data$index)

dfmat <- corp %>% tokens(remove_punc=TRUE) %>%
  dfm()

sim_mat <- textstat_simil(dfmat, method="cosine")
sim_df <- as.data.frame(sim_mat, upper=TRUE)

sim_filt <- sim_df %>% filter(cosine >= 0.7) # threshold for duplicate

lab_copy <- lab_data # create a copy 
lab_copy$cos_dup <- NA

for (i in 1:nrow(sim_filt)) {        # remove duplicates with different countries
  index1 = as.numeric(sim_filt[i,1])
  index2 = as.numeric(sim_filt[i,2])
  if(lab_copy[index1,2]!=lab_copy[index2,2]){
    sim_filt[i, 3] = NA
    sim_filt_2 <- na.omit(sim_filt)
    }
}
for (i in 1:nrow(sim_filt_2)){       # labeling 
  index1 = as.numeric(sim_filt_2[i,1])
  lab_copy[index1,12] = paste(lab_copy[index1,12], sim_filt_2[i,2], sep = ",")}

lab_copy$cos_dup <- trimws(lab_copy$cos_dup, whitespace = "NA,")

lab_copy %>% 
  mutate(cos_dup_n = ifelse(is.na(cos_dup) == F, 1, 0)) %>% 
  #count(cos_dup_n) %>% # 1274 detected duplicates out of 3492 %>% 
  group_by(country) %>% 
  ggplot(aes(x = country, y = (cos_dup_n))) + geom_col(width = 0.8) + ggtitle("Detected dups per country - CERES trial") + theme_bw()

lab_copy %>% 
  mutate(cos_dup_n = ifelse(is.na(cos_dup) == F, 1, 0)) %>% 
  count(cos_dup_n) # 1274 detected duplicates out of 3492


```

################################################################################

```{r}
dup <- read_csv("C:\\Users\\laura\\OneDrive\\Documenti\\LAURA\\MCC\\Policy databases\\duplicates_1.csv")

filt_dup <- dup %>% filter(`Country Code` %in% c("AUS", "AUT","BEL", "CAN", "DNK", "FIN", "FRA", "DEU", "GRC",
                      "IRL", "ITA", "JPN", "LUX", "NLD", "NZL", "PRT", "ESP", "SWE",
                      "CHE", "GBR", "USA"))

filt_dup %>% group_by(indicator_database_source) %>% count()

uni <- unique(filt_dup$`Policy Name`)
uni 
```


